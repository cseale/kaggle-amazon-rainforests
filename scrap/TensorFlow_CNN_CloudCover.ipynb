{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from random import shuffle\n",
    "from tqdm import tqdm\n",
    "\n",
    "DATA_DIR = '../input/amazon/'\n",
    "TRAIN_TIF_DIR = DATA_DIR + 'train-tif-v2/'\n",
    "TRAIN_CSV = DATA_DIR + 'train.csv'\n",
    "TEST_TIF_DIR = DATA_DIR + 'test-tif/'\n",
    "\n",
    "IMG_SIZE = 100\n",
    "LR = 1e-3\n",
    "\n",
    "MODEL_NAME = 'amazon=-{}-{}.model'.format(LR, '2conv-basic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_name</th>\n",
       "      <th>tags</th>\n",
       "      <th>clear</th>\n",
       "      <th>cloudy</th>\n",
       "      <th>haze</th>\n",
       "      <th>partly_cloudy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0</td>\n",
       "      <td>haze primary</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1</td>\n",
       "      <td>agriculture clear primary water</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  image_name                             tags  clear  cloudy  haze  \\\n",
       "0    train_0                     haze primary      0       0     1   \n",
       "1    train_1  agriculture clear primary water      1       0     0   \n",
       "\n",
       "   partly_cloudy  \n",
       "0              0  \n",
       "1              0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLOUD_COVER_LABELS = [\n",
    "    'clear', \n",
    "    'cloudy', \n",
    "    'haze', \n",
    "    'partly_cloudy']\n",
    "\n",
    "# read our data and take a look at what we are dealing with\n",
    "train_csv = pd.read_csv(TRAIN_CSV)\n",
    "train_csv.head()\n",
    "\n",
    "tags = pd.DataFrame()\n",
    "\n",
    "for label in CLOUD_COVER_LABELS:\n",
    "    tags[label] = train_csv.tags.apply(lambda x: np.where(label in x, 1, 0))\n",
    "    \n",
    "train_csv = pd.concat([train_csv, tags], axis=1)\n",
    "train_csv.head(n=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "clear            28203\n",
       "cloudy            9581\n",
       "haze              2695\n",
       "partly_cloudy     7251\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# need to fix class imbalance\n",
    "train_csv[['clear', 'cloudy', 'haze', 'partly_cloudy']].sum()\n",
    "\n",
    "# add class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# limit to 1000, remove this in real script\n",
    "train = train_csv[0:1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from skimage import io\n",
    "from scipy.misc import imresize\n",
    "import cv2\n",
    "import tifffile as tiff\n",
    "\n",
    "# convert cloud cover labels to array [clear, cloudy, haze, partly_cloudy]\n",
    "def get_cloud_cover_labels(row):\n",
    "    labels = np.array([row.clear, row.cloudy, row.haze, row.partly_cloudy])\n",
    "    return labels\n",
    "\n",
    "# load image\n",
    "# reduce image from 255,255,4 to 100,100,4\n",
    "# flatten out to 1-D array in order R,G,B,NIR (should we use greyscale instead, ignore NIR?)\n",
    "def load_image(filename):\n",
    "    path = os.path.abspath(os.path.join(TRAIN_TIF_DIR, filename))\n",
    "    if os.path.exists(path):\n",
    "        img = tiff.imread(path)[:,:,:3]\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "        return img\n",
    "    # if you reach this line, you didn't find the image you're looking for\n",
    "    print('Load failed: could not find image {}'.format(path))\n",
    "    \n",
    "# create training data from train.csv DataFrame\n",
    "def create_training_data():\n",
    "    train_images = []\n",
    "\n",
    "    for index, row in tqdm(train.iterrows()):\n",
    "        grey_image = load_image(row.image_name + '.tif')\n",
    "        train_images.append([grey_image, \n",
    "                             get_cloud_cover_labels(row),\n",
    "                             row.image_name])\n",
    "\n",
    "    np.save('training_images.npy', train_images)\n",
    "    return train_images\n",
    "\n",
    "# load test data from test data folder\n",
    "# reduce image to 100,100,4, flatten etc as above\n",
    "def create_test_data():\n",
    "    test_images = []\n",
    "    \n",
    "    for image_name in os.listdir(TRAIN_TIF_DIR):\n",
    "        grey_image = load_image(row.image_name + '.tif')\n",
    "        test_images.append([grey_image, image_name.split('.')[0]])\n",
    "        \n",
    "    return test_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1000it [00:10, 92.99it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# at this point we have our training data in a list\n",
    "# [0] - greyscale rgbn image\n",
    "# [1] - array of labels where clear, cloudy, haze, partly_cloudy\n",
    "# [2] - name of image, for reference\n",
    "\n",
    "train_images = create_training_data()\n",
    "len(train_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import cv2\n",
    "# import matplotlib.pyplot as plt\n",
    "# import tifffile as tiff\n",
    "\n",
    "# # path = os.path.abspath(os.path.join(TRAIN_TIF_DIR, 'train_3675.tif'))\n",
    "# path = os.path.abspath(os.path.join(TRAIN_TIF_DIR, 'train_19.tif'))\n",
    "# img = tiff.imread(path)[:,:,:3]\n",
    "# img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "# img = cv2.resize(img, (IMG_SIZE, IMG_SIZE))\n",
    "# plt.imshow(img, cmap='gray')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if you need to load the training data\n",
    "# train_images = np.load('training_images.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "tf.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tflearn\n",
    "from tflearn.layers.conv import conv_2d, max_pool_2d\n",
    "from tflearn.layers.core import input_data, dropout, fully_connected\n",
    "from tflearn.layers.estimator import regression\n",
    "\n",
    "convnet = input_data(shape=[None, IMG_SIZE, IMG_SIZE, 1], name='input')\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 128, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 64, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = conv_2d(convnet, 32, 5, activation='relu')\n",
    "convnet = max_pool_2d(convnet, 5)\n",
    "\n",
    "convnet = fully_connected(convnet, 1024, activation='relu')\n",
    "convnet = dropout(convnet, 0.8)\n",
    "\n",
    "convnet = fully_connected(convnet, 4, activation='softmax')\n",
    "convnet = regression(convnet, optimizer='adam', learning_rate=LR, loss='categorical_crossentropy', name='targets')\n",
    "\n",
    "model = tflearn.DNN(convnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if os.path.exists('{}.meta'.format(MODEL_NAME)):\n",
    "    model.load(MODEL_NAME)\n",
    "    print('model loaded!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = train_images[:-8000]\n",
    "# need a cross validation set\n",
    "cv_data = train_images[-8000:-4000]\n",
    "test_data = train_images[-4000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X = np.array([i[0] for i in train_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y = [i[1] for i in train_data]\n",
    "\n",
    "X_test = np.array([i[0] for i in test_data]).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n",
    "y_test = [i[1] for i in test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Step: 11  | total loss: \u001b[1m\u001b[32m11.64486\u001b[0m\u001b[0m | time: 28.780s\n",
      "\u001b[2K\r",
      "| Adam | epoch: 001 | loss: 11.64486 - acc: 0.6889 -- iter: 704/900\n"
     ]
    }
   ],
   "source": [
    "model.fit({'input': X}, {'targets': Y}, n_epoch=3, validation_set=({'input': X_test}, {'targets': y_test}), \n",
    "    snapshot_step=500, show_metric=True, run_id=MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model.save('/output/' + MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# need to measure F2 score instead of accuracy"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
